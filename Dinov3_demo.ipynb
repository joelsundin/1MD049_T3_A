{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import glob\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import cv2\n",
        "import torch\n",
        "from torchvision import transforms\n",
        "import torch.nn.functional as F\n",
        "import random\n",
        "from torchvision.transforms import v2\n",
        "from matplotlib import colormaps\n",
        "import io\n"
      ],
      "metadata": {
        "id": "j5AJMEv90kjX"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/facebookresearch/dinov3.git\n",
        "%cd dinov3\n",
        "!pip install -r requirements.txt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-YdP0fKv0nd9",
        "outputId": "3863ca34-1088-46f8-f9a9-43fec1b8b1da"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'dinov3'...\n",
            "remote: Enumerating objects: 538, done.\u001b[K\n",
            "remote: Counting objects: 100% (363/363), done.\u001b[K\n",
            "remote: Compressing objects: 100% (264/264), done.\u001b[K\n",
            "remote: Total 538 (delta 201), reused 99 (delta 99), pack-reused 175 (from 1)\u001b[K\n",
            "Receiving objects: 100% (538/538), 9.88 MiB | 25.68 MiB/s, done.\n",
            "Resolving deltas: 100% (223/223), done.\n",
            "/content/dinov3\n",
            "Collecting ftfy (from -r requirements.txt (line 1))\n",
            "  Downloading ftfy-6.3.1-py3-none-any.whl.metadata (7.3 kB)\n",
            "Requirement already satisfied: omegaconf in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 2)) (2.3.0)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 3)) (2025.11.3)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 4)) (1.6.1)\n",
            "Collecting submitit (from -r requirements.txt (line 5))\n",
            "  Downloading submitit-1.5.3-py3-none-any.whl.metadata (7.9 kB)\n",
            "Requirement already satisfied: termcolor in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 6)) (3.2.0)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 7)) (2.9.0+cu126)\n",
            "Collecting torchmetrics (from -r requirements.txt (line 8))\n",
            "  Downloading torchmetrics-1.8.2-py3-none-any.whl.metadata (22 kB)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 9)) (0.24.0+cu126)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.12/dist-packages (from ftfy->-r requirements.txt (line 1)) (0.2.14)\n",
            "Requirement already satisfied: antlr4-python3-runtime==4.9.* in /usr/local/lib/python3.12/dist-packages (from omegaconf->-r requirements.txt (line 2)) (4.9.3)\n",
            "Requirement already satisfied: PyYAML>=5.1.0 in /usr/local/lib/python3.12/dist-packages (from omegaconf->-r requirements.txt (line 2)) (6.0.3)\n",
            "Requirement already satisfied: numpy>=1.19.5 in /usr/local/lib/python3.12/dist-packages (from scikit-learn->-r requirements.txt (line 4)) (2.0.2)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn->-r requirements.txt (line 4)) (1.16.3)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn->-r requirements.txt (line 4)) (1.5.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn->-r requirements.txt (line 4)) (3.6.0)\n",
            "Requirement already satisfied: cloudpickle>=1.2.1 in /usr/local/lib/python3.12/dist-packages (from submitit->-r requirements.txt (line 5)) (3.1.2)\n",
            "Requirement already satisfied: typing_extensions>=3.7.4.2 in /usr/local/lib/python3.12/dist-packages (from submitit->-r requirements.txt (line 5)) (4.15.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch->-r requirements.txt (line 7)) (3.20.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch->-r requirements.txt (line 7)) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch->-r requirements.txt (line 7)) (1.14.0)\n",
            "Requirement already satisfied: networkx>=2.5.1 in /usr/local/lib/python3.12/dist-packages (from torch->-r requirements.txt (line 7)) (3.6.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch->-r requirements.txt (line 7)) (3.1.6)\n",
            "Requirement already satisfied: fsspec>=0.8.5 in /usr/local/lib/python3.12/dist-packages (from torch->-r requirements.txt (line 7)) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch->-r requirements.txt (line 7)) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch->-r requirements.txt (line 7)) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch->-r requirements.txt (line 7)) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch->-r requirements.txt (line 7)) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch->-r requirements.txt (line 7)) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch->-r requirements.txt (line 7)) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch->-r requirements.txt (line 7)) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch->-r requirements.txt (line 7)) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch->-r requirements.txt (line 7)) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch->-r requirements.txt (line 7)) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.5 in /usr/local/lib/python3.12/dist-packages (from torch->-r requirements.txt (line 7)) (2.27.5)\n",
            "Requirement already satisfied: nvidia-nvshmem-cu12==3.3.20 in /usr/local/lib/python3.12/dist-packages (from torch->-r requirements.txt (line 7)) (3.3.20)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch->-r requirements.txt (line 7)) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch->-r requirements.txt (line 7)) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch->-r requirements.txt (line 7)) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.5.0 in /usr/local/lib/python3.12/dist-packages (from torch->-r requirements.txt (line 7)) (3.5.0)\n",
            "Requirement already satisfied: packaging>17.1 in /usr/local/lib/python3.12/dist-packages (from torchmetrics->-r requirements.txt (line 8)) (25.0)\n",
            "Collecting lightning-utilities>=0.8.0 (from torchmetrics->-r requirements.txt (line 8))\n",
            "  Downloading lightning_utilities-0.15.2-py3-none-any.whl.metadata (5.7 kB)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.12/dist-packages (from torchvision->-r requirements.txt (line 9)) (11.3.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch->-r requirements.txt (line 7)) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch->-r requirements.txt (line 7)) (3.0.3)\n",
            "Downloading ftfy-6.3.1-py3-none-any.whl (44 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.8/44.8 kB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading submitit-1.5.3-py3-none-any.whl (75 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.5/75.5 kB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading torchmetrics-1.8.2-py3-none-any.whl (983 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m983.2/983.2 kB\u001b[0m \u001b[31m35.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading lightning_utilities-0.15.2-py3-none-any.whl (29 kB)\n",
            "Installing collected packages: submitit, lightning-utilities, ftfy, torchmetrics\n",
            "Successfully installed ftfy-6.3.1 lightning-utilities-0.15.2 submitit-1.5.3 torchmetrics-1.8.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0tEkCAouz9wX",
        "outputId": "63d924ae-d1b2-4e68-966a-5320e8e58b92"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-12-17 10:28:52--  https://dinov3.llamameta.net/dinov3_vitb16/dinov3_vitb16_pretrain_lvd1689m-73cec8be.pth?Policy=eyJTdGF0ZW1lbnQiOlt7InVuaXF1ZV9oYXNoIjoiNXF0a3Q0djl5ZDZkMDlncXdmeno5MHB2IiwiUmVzb3VyY2UiOiJodHRwczpcL1wvZGlub3YzLmxsYW1hbWV0YS5uZXRcLyoiLCJDb25kaXRpb24iOnsiRGF0ZUxlc3NUaGFuIjp7IkFXUzpFcG9jaFRpbWUiOjE3NjU5OTA0Nzh9fX1dfQ__&Signature=GOt0pzYq7KdFRXWv1yeCglKsLWadjmTN-ifqlB0gyJu4ZV5VQ8z2f%7EDW9KouJc7dmXCfblmaDt0PUcKR-6Qy%7EORLqF5LMaO8yy8jI3jhJDePq4w0qxAClyu7YYDaYOTvf4k%7E75PuWacsDBMPla5%7ExVspMQwuaYRNQc-qmshmukfCyGZdnljxj6EQIeI3qq5huyOcVyO-Jq9K78nf7HjWxBg2TUM%7Evw53hFDAn3yNQo%7EcsQaEoRgECa1nvYDhyb6j-qbhVhZHszojipU09CRAeuDfyeksPFs8B2TE2FXM8rXYaYSEnHfJ9s%7EhwneyohvZqS4XOOlZUy%7EIw--7-e5nHw__&Key-Pair-Id=K15QRJLYKIFSLZ&Download-Request-ID=1912522716015463\n",
            "Resolving dinov3.llamameta.net (dinov3.llamameta.net)... 3.165.160.25, 3.165.160.69, 3.165.160.34, ...\n",
            "Connecting to dinov3.llamameta.net (dinov3.llamameta.net)|3.165.160.25|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 342860279 (327M) [binary/octet-stream]\n",
            "Saving to: ‘dinov3_vitb16_pretrain_lvd1689m-73cec8be.pth’\n",
            "\n",
            "dinov3_vitb16_pretr 100%[===================>] 326.98M   175MB/s    in 1.9s    \n",
            "\n",
            "2025-12-17 10:28:56 (175 MB/s) - ‘dinov3_vitb16_pretrain_lvd1689m-73cec8be.pth’ saved [342860279/342860279]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!wget \"\" -O \"dinov3_vitb16_pretrain_lvd1689m-73cec8be.pth\""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "REPO_DIR = \"/content/dinov3\"\n",
        "WEIGHTS = \"/content/dinov3/dinov3_vitb16_pretrain_lvd1689m-73cec8be.pth\"\n",
        "dinov3_vitb16 = torch.hub.load(REPO_DIR, 'dinov3_vitb16', source='local', weights=WEIGHTS)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DCrGUKXP0pEM",
        "outputId": "b3a9bd37-61a7-4d9e-b9aa-e356f03f551c"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading: \"file:///content/dinov3/dinov3_vitb16_pretrain_lvd1689m-73cec8be.pth\" to /root/.cache/torch/hub/checkpoints/dinov3_vitb16_pretrain_lvd1689m-73cec8be.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 327M/327M [00:00<00:00, 711MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "dinov3_vitb16\n",
        "dinov3_vitb16.eval()\n",
        "dinov3_vitb16.to(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C839Mr4F1EIb",
        "outputId": "5ccd0228-106b-4d9a-babf-3b0dd632072a"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DinoVisionTransformer(\n",
              "  (patch_embed): PatchEmbed(\n",
              "    (proj): Conv2d(3, 768, kernel_size=(16, 16), stride=(16, 16))\n",
              "    (norm): Identity()\n",
              "  )\n",
              "  (rope_embed): RopePositionEmbedding()\n",
              "  (blocks): ModuleList(\n",
              "    (0-11): 12 x SelfAttentionBlock(\n",
              "      (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "      (attn): SelfAttention(\n",
              "        (qkv): LinearKMaskedBias(in_features=768, out_features=2304, bias=True)\n",
              "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
              "        (proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
              "      )\n",
              "      (ls1): LayerScale()\n",
              "      (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "      (mlp): Mlp(\n",
              "        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        (act): GELU(approximate='none')\n",
              "        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        (drop): Dropout(p=0.0, inplace=False)\n",
              "      )\n",
              "      (ls2): LayerScale()\n",
              "    )\n",
              "  )\n",
              "  (norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "  (head): Identity()\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def make_transform(resize_size: int = 2048):\n",
        "    to_tensor = transforms.v2.ToImage()\n",
        "    resize = transforms.v2.Resize((resize_size, resize_size), antialias=True)\n",
        "    to_float = transforms.v2.ToDtype(torch.float32, scale=True)\n",
        "    normalize = transforms.v2.Normalize(\n",
        "        mean=(0.485, 0.456, 0.406),\n",
        "        std=(0.229, 0.224, 0.225),\n",
        "    )\n",
        "    return transforms.v2.Compose([to_tensor, resize, to_float, normalize])\n",
        "\n",
        "def patch_embeddings(img, resize_dim):\n",
        "    transform = make_transform(resize_dim).to(device)\n",
        "    x = transform(img).unsqueeze(0).to(device)\n",
        "\n",
        "    with torch.no_grad():\n",
        "      features_dict = dinov3_vitb16.forward_features(x)\n",
        "      patch_features = features_dict['x_norm_patchtokens']\n",
        "    return patch_features\n",
        "\n",
        "def patch_map(patch_embeddings):\n",
        "  patch_norms = patch_embeddings.norm(dim=-1).squeeze()\n",
        "  grid_size = int(patch_norms.shape[0] ** 0.5)\n",
        "  patch_map = patch_norms.reshape(grid_size, grid_size).cpu().numpy()\n",
        "  return patch_map\n",
        "\n",
        "def heatmap_overlay(image: Image.Image, patch_map: np.ndarray):\n",
        "    # resize patch map to fit img\n",
        "    heatmap = Image.fromarray(patch_map)\n",
        "    heatmap = heatmap.resize(image.size, resample=Image.BILINEAR)\n",
        "    heatmap = np.array(heatmap)\n",
        "\n",
        "    heatmap = (heatmap - heatmap.min()) / (heatmap.max() - heatmap.min() + 1e-6)\n",
        "\n",
        "    fig, ax = plt.subplots()\n",
        "    #ax.imshow(image)\n",
        "    #ax.imshow(heatmap, cmap=\"jet\", alpha=0.5)\n",
        "    ax.imshow(heatmap)\n",
        "    ax.axis(\"off\")\n",
        "\n",
        "    buf = io.BytesIO()\n",
        "    plt.savefig(buf, format=\"png\", bbox_inches=\"tight\", pad_inches=0)\n",
        "    plt.close(fig)\n",
        "    buf.seek(0)\n",
        "    return Image.open(buf)\n",
        "\n",
        "\n",
        "def process_image(img):\n",
        "    if not isinstance(img, Image.Image):\n",
        "        img = Image.fromarray(img)\n",
        "\n",
        "    patches = patch_embeddings(img, resize_dim=2048)\n",
        "    pmap = patch_map(patches)\n",
        "\n",
        "    heatmap_img = heatmap_overlay(img, pmap)\n",
        "    patch_map_img = Image.fromarray(\n",
        "        ((pmap - pmap.min()) / (pmap.max() - pmap.min()) * 255).astype(np.uint8)\n",
        "    )\n",
        "\n",
        "    embedding_stats = {\n",
        "        \"num_patches\": patches.shape[1],\n",
        "        \"embedding_dim\": patches.shape[2],\n",
        "    }\n",
        "\n",
        "    return img, patch_map_img, heatmap_img, embedding_stats\n",
        "\n",
        "def extract_and_cache_tokens(img, resize_dim=2048):\n",
        "    patches = patch_embeddings(img, resize_dim)[0]  # (N, D)\n",
        "    patches = torch.nn.functional.normalize(patches, dim=1)\n",
        "\n",
        "    grid_size = int(patches.shape[0] ** 0.5)\n",
        "    return patches, grid_size\n",
        "\n",
        "def pixel_to_patch_index(x, y, image_size, grid_size):\n",
        "    H, W = image_size\n",
        "    patch_h = H // grid_size\n",
        "    patch_w = W // grid_size\n",
        "\n",
        "    px = min(x // patch_w, grid_size - 1)\n",
        "    py = min(y // patch_h, grid_size - 1)\n",
        "\n",
        "    index = py * grid_size + px\n",
        "    return index, px, py\n",
        "\n",
        "def cosine_similarity_map(tokens, query_index, grid_size):\n",
        "  query = tokens[query_index]        # (D,)\n",
        "  similarities = tokens @ query      # (N,)\n",
        "  sim_map = similarities.reshape(grid_size, grid_size)\n",
        "  return sim_map.cpu().numpy()\n",
        "\n",
        "def on_click(img, cached_tokens, cached_grid, evt: gr.SelectData):\n",
        "    x, y = evt.index\n",
        "\n",
        "    H, W = img.size[1], img.size[0]\n",
        "    patch_idx, px, py = pixel_to_patch_index(\n",
        "        x, y, (H, W), cached_grid\n",
        "    )\n",
        "\n",
        "    sim_map = cosine_similarity_map(\n",
        "        cached_tokens, patch_idx, cached_grid\n",
        "    )\n",
        "\n",
        "    heatmap = heatmap_overlay(img, sim_map)\n",
        "\n",
        "    info = {\n",
        "        \"clicked_pixel\": (x, y),\n",
        "        \"patch_index\": int(patch_idx),\n",
        "        \"patch_coords\": (int(px), int(py)),\n",
        "    }\n",
        "\n",
        "    return heatmap, info\n",
        "\n"
      ],
      "metadata": {
        "id": "v_SBFmvM1Fv1"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import gradio as gr\n",
        "\n",
        "with gr.Blocks() as demo:\n",
        "    gr.Markdown(\"## Patch Embeddings & Click-to-Cosine Similarity\")\n",
        "    cached_tokens = gr.State()\n",
        "    cached_grid = gr.State()\n",
        "\n",
        "    with gr.Row():\n",
        "        input_img = gr.Image(\n",
        "            type=\"pil\",\n",
        "            label=\"Input Image (click to query patch)\", height=640\n",
        "        )\n",
        "\n",
        "    with gr.Row():\n",
        "        patch_map_img = gr.Image(label=\"Norm map, 1 pixel = 1 ViT patch\", height=1024)\n",
        "        heatmap_out = gr.Image(label=\"Cosine Similarity Heatmap\", height=640)\n",
        "\n",
        "    info_out = gr.JSON(label=\"Click\")\n",
        "\n",
        "    def on_image_upload(img):\n",
        "        tokens, grid = extract_and_cache_tokens(img, resize_dim=2048)\n",
        "        pmap = patch_map(tokens.unsqueeze(0))\n",
        "        pmap_img = Image.fromarray(\n",
        "            ((pmap - pmap.min()) / (pmap.max() - pmap.min()) * 255).astype(\"uint8\")\n",
        "        )\n",
        "\n",
        "        return tokens, grid, pmap_img\n",
        "\n",
        "    input_img.change(\n",
        "        fn=on_image_upload,\n",
        "        inputs=input_img,\n",
        "        outputs=[cached_tokens, cached_grid, patch_map_img],\n",
        "    )\n",
        "\n",
        "    input_img.select(\n",
        "      fn=on_click,\n",
        "      inputs=[input_img, cached_tokens, cached_grid],\n",
        "      outputs=[heatmap_out, info_out],\n",
        "    )\n",
        "\n",
        "\n",
        "demo.launch(debug=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "SIp5T4wo2sU5",
        "outputId": "b702dfa0-ea30-482c-b1c3-cc7514297d7e"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "It looks like you are running Gradio on a hosted Jupyter notebook, which requires `share=True`. Automatically setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. This cell will run indefinitely so that you can see errors and logs. To turn off, set debug=False in launch().\n",
            "* Running on public URL: https://adb69ac600e00d955e.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://adb69ac600e00d955e.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "ERROR:    Exception in ASGI application\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/uvicorn/protocols/http/h11_impl.py\", line 403, in run_asgi\n",
            "    result = await app(  # type: ignore[func-returns-value]\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/uvicorn/middleware/proxy_headers.py\", line 60, in __call__\n",
            "    return await self.app(scope, receive, send)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/fastapi/applications.py\", line 1133, in __call__\n",
            "    await super().__call__(scope, receive, send)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/starlette/applications.py\", line 113, in __call__\n",
            "    await self.middleware_stack(scope, receive, send)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/starlette/middleware/errors.py\", line 186, in __call__\n",
            "    raise exc\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/starlette/middleware/errors.py\", line 164, in __call__\n",
            "    await self.app(scope, receive, _send)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/gradio/brotli_middleware.py\", line 74, in __call__\n",
            "    return await self.app(scope, receive, send)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/gradio/route_utils.py\", line 882, in __call__\n",
            "    await self.app(scope, receive, send)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/starlette/middleware/exceptions.py\", line 63, in __call__\n",
            "    await wrap_app_handling_exceptions(self.app, conn)(scope, receive, send)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/starlette/_exception_handler.py\", line 53, in wrapped_app\n",
            "    raise exc\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/starlette/_exception_handler.py\", line 42, in wrapped_app\n",
            "    await app(scope, receive, sender)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/fastapi/middleware/asyncexitstack.py\", line 18, in __call__\n",
            "    await self.app(scope, receive, send)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/starlette/routing.py\", line 716, in __call__\n",
            "    await self.middleware_stack(scope, receive, send)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/starlette/routing.py\", line 736, in app\n",
            "    await route.handle(scope, receive, send)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/starlette/routing.py\", line 290, in handle\n",
            "    await self.app(scope, receive, send)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/fastapi/routing.py\", line 123, in app\n",
            "    await wrap_app_handling_exceptions(app, request)(scope, receive, send)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/starlette/_exception_handler.py\", line 53, in wrapped_app\n",
            "    raise exc\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/starlette/_exception_handler.py\", line 42, in wrapped_app\n",
            "    await app(scope, receive, sender)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/fastapi/routing.py\", line 109, in app\n",
            "    response = await f(request)\n",
            "               ^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/fastapi/routing.py\", line 387, in app\n",
            "    raw_response = await run_endpoint_function(\n",
            "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/fastapi/routing.py\", line 288, in run_endpoint_function\n",
            "    return await dependant.call(**values)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/gradio/routes.py\", line 1671, in get_upload_progress\n",
            "    await asyncio.wait_for(\n",
            "  File \"/usr/lib/python3.12/asyncio/tasks.py\", line 520, in wait_for\n",
            "    return await fut\n",
            "           ^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/gradio/route_utils.py\", line 528, in is_tracked\n",
            "    return await self._signals[upload_id].wait()\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.12/asyncio/locks.py\", line 209, in wait\n",
            "    fut = self._get_loop().create_future()\n",
            "          ^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.12/asyncio/mixins.py\", line 20, in _get_loop\n",
            "    raise RuntimeError(f'{self!r} is bound to a different event loop')\n",
            "RuntimeError: <asyncio.locks.Event object at 0x788c068494c0 [unset]> is bound to a different event loop\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Keyboard interruption in main thread... closing server.\n",
            "Killing tunnel 127.0.0.1:7860 <> https://adb69ac600e00d955e.gradio.live\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "yRGBgnLb7_Y-"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}